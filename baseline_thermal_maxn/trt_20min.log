&&&& RUNNING TensorRT.trtexec [TensorRT v100300] # trtexec --loadEngine=/home/yuanyang/models/resnet50_fp16.engine --warmUp=200 --duration=1200 --useSpinWait --streams=2
[02/23/2026-21:13:39] [W] --streams flag has been deprecated, use --infStreams flag instead.
[02/23/2026-21:13:39] [I] === Model Options ===
[02/23/2026-21:13:39] [I] Format: *
[02/23/2026-21:13:39] [I] Model: 
[02/23/2026-21:13:39] [I] Output:
[02/23/2026-21:13:39] [I] 
[02/23/2026-21:13:39] [I] === System Options ===
[02/23/2026-21:13:39] [I] Device: 0
[02/23/2026-21:13:39] [I] DLACore: 
[02/23/2026-21:13:39] [I] Plugins:
[02/23/2026-21:13:39] [I] setPluginsToSerialize:
[02/23/2026-21:13:39] [I] dynamicPlugins:
[02/23/2026-21:13:39] [I] ignoreParsedPluginLibs: 0
[02/23/2026-21:13:39] [I] 
[02/23/2026-21:13:39] [I] === Inference Options ===
[02/23/2026-21:13:39] [I] Batch: Explicit
[02/23/2026-21:13:39] [I] Input inference shapes: model
[02/23/2026-21:13:39] [I] Iterations: 10
[02/23/2026-21:13:39] [I] Duration: 1200s (+ 200ms warm up)
[02/23/2026-21:13:39] [I] Sleep time: 0ms
[02/23/2026-21:13:39] [I] Idle time: 0ms
[02/23/2026-21:13:39] [I] Inference Streams: 2
[02/23/2026-21:13:39] [I] ExposeDMA: Disabled
[02/23/2026-21:13:39] [I] Data transfers: Enabled
[02/23/2026-21:13:39] [I] Spin-wait: Enabled
[02/23/2026-21:13:39] [I] Multithreading: Disabled
[02/23/2026-21:13:39] [I] CUDA Graph: Disabled
[02/23/2026-21:13:39] [I] Separate profiling: Disabled
[02/23/2026-21:13:39] [I] Time Deserialize: Disabled
[02/23/2026-21:13:39] [I] Time Refit: Disabled
[02/23/2026-21:13:39] [I] NVTX verbosity: 0
[02/23/2026-21:13:39] [I] Persistent Cache Ratio: 0
[02/23/2026-21:13:39] [I] Optimization Profile Index: 0
[02/23/2026-21:13:39] [I] Weight Streaming Budget: 100.000000%
[02/23/2026-21:13:39] [I] Inputs:
[02/23/2026-21:13:39] [I] Debug Tensor Save Destinations:
[02/23/2026-21:13:39] [I] === Reporting Options ===
[02/23/2026-21:13:39] [I] Verbose: Disabled
[02/23/2026-21:13:39] [I] Averages: 10 inferences
[02/23/2026-21:13:39] [I] Percentiles: 90,95,99
[02/23/2026-21:13:39] [I] Dump refittable layers:Disabled
[02/23/2026-21:13:39] [I] Dump output: Disabled
[02/23/2026-21:13:39] [I] Profile: Disabled
[02/23/2026-21:13:39] [I] Export timing to JSON file: 
[02/23/2026-21:13:39] [I] Export output to JSON file: 
[02/23/2026-21:13:39] [I] Export profile to JSON file: 
[02/23/2026-21:13:39] [I] 
[02/23/2026-21:13:39] [I] === Device Information ===
[02/23/2026-21:13:39] [I] Available Devices: 
[02/23/2026-21:13:39] [I]   Device 0: "Orin" UUID: GPU-158fe06a-969b-59bf-bf6e-7fd93044f760
[02/23/2026-21:13:39] [I] Selected Device: Orin
[02/23/2026-21:13:39] [I] Selected Device ID: 0
[02/23/2026-21:13:39] [I] Selected Device UUID: GPU-158fe06a-969b-59bf-bf6e-7fd93044f760
[02/23/2026-21:13:39] [I] Compute Capability: 8.7
[02/23/2026-21:13:39] [I] SMs: 8
[02/23/2026-21:13:39] [I] Device Global Memory: 7620 MiB
[02/23/2026-21:13:39] [I] Shared Memory per SM: 164 KiB
[02/23/2026-21:13:39] [I] Memory Bus Width: 128 bits (ECC disabled)
[02/23/2026-21:13:39] [I] Application Compute Clock Rate: 1.02 GHz
[02/23/2026-21:13:39] [I] Application Memory Clock Rate: 1.02 GHz
[02/23/2026-21:13:39] [I] 
[02/23/2026-21:13:39] [I] Note: The application clock rates do not reflect the actual clock rates that the GPU is currently running at.
[02/23/2026-21:13:39] [I] 
[02/23/2026-21:13:39] [I] TensorRT version: 10.3.0
[02/23/2026-21:13:39] [I] Loading standard plugins
[02/23/2026-21:13:39] [I] [TRT] Loaded engine size: 49 MiB
[02/23/2026-21:13:39] [I] Engine deserialized in 0.0929901 sec.
[02/23/2026-21:13:39] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +4, now: CPU 0, GPU 52 (MiB)
[02/23/2026-21:13:39] [I] Setting persistentCacheLimit to 0 bytes.
[02/23/2026-21:13:39] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +5, now: CPU 0, GPU 57 (MiB)
[02/23/2026-21:13:39] [I] Setting persistentCacheLimit to 0 bytes.
[02/23/2026-21:13:39] [I] Created execution context with device memory size: 4.21094 MiB
[02/23/2026-21:13:39] [I] Created execution context with device memory size: 4.21094 MiB
[02/23/2026-21:13:39] [I] Using random values for input data
[02/23/2026-21:13:39] [I] Input binding for data with dimensions 1x3x224x224 is created.
[02/23/2026-21:13:39] [I] Using random values for input data
[02/23/2026-21:13:39] [I] Input binding for data with dimensions 1x3x224x224 is created.
[02/23/2026-21:13:39] [I] Output binding for resnetv24_dense0_fwd with dimensions 1x1000 is created.
[02/23/2026-21:13:39] [I] Output binding for resnetv24_dense0_fwd with dimensions 1x1000 is created.
[02/23/2026-21:13:39] [I] Starting inference
